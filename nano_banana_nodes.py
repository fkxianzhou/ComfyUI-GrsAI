"""
ComfyUIèŠ‚ç‚¹å®ç°
å®šä¹‰ Nano Banana å›¾åƒç”ŸæˆèŠ‚ç‚¹ï¼ˆæ–‡ç”Ÿå›¾ / å›¾ç”Ÿå›¾ / å¤šå›¾ï¼‰
"""

import os
import tempfile
import logging
from typing import Any, Tuple, Optional, Dict, List

import torch

# å°è¯•ç›¸å¯¹å¯¼å…¥ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨ç»å¯¹å¯¼å…¥
try:
    from .upload import upload_file_zh
    from .api_client import GrsaiAPI, GrsaiAPIError
    from .config import default_config
    from .utils import (
        pil_to_tensor,
        format_error_message,
        tensor_to_pil,
    )
except ImportError:
    from upload import upload_file_zh
    from api_client import GrsaiAPI, GrsaiAPIError
    from config import default_config
    from utils import pil_to_tensor, format_error_message, tensor_to_pil


class SuppressFalLogs:
    """ä¸´æ—¶æŠ‘åˆ¶HTTPç›¸å…³çš„è¯¦ç»†æ—¥å¿—çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""

    def __init__(self):
        self.loggers_to_suppress = [
            "httpx",
            "httpcore",
            "urllib3.connectionpool",
        ]
        self.original_levels: Dict[str, int] = {}

    def __enter__(self):
        for logger_name in self.loggers_to_suppress:
            logger = logging.getLogger(logger_name)
            self.original_levels[logger_name] = logger.level
            logger.setLevel(logging.WARNING)
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        for logger_name, original_level in self.original_levels.items():
            logging.getLogger(logger_name).setLevel(original_level)


class GrsaiNanoBanana_Node:
    """
    Nano Banana å›¾åƒç”ŸæˆèŠ‚ç‚¹
    - å¯é€‰å¤šå›¾ä½œä¸ºå‚è€ƒï¼šä¸è¾“å…¥å›¾åƒæ—¶ä¸ºæ–‡ç”Ÿå›¾ï¼›è¾“å…¥1å¼ æˆ–å¤šå¼ æ—¶ä¸ºå›¾ç”Ÿå›¾
    """

    FUNCTION = "execute"
    CATEGORY = "GrsAI/Nano Banana"

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": (
                    "STRING",
                    {
                        "multiline": True,
                        "default": "Create a high-quality studio shot of a ripe banana on a matte surface, soft shadows, natural lighting.",
                    },
                ),
                "model": (
                    ["nano-banana", "nano-banana-fast", "nano-banana-pro"],
                    {"default": "nano-banana-fast"},
                ),
                "imageSize": (
                    default_config.SUPPORTED_NANO_BANANA_SIZES,
                    {"default": "1K"},
                ),
            },
            "optional": {
                "use_aspect_ratio": ("BOOLEAN", {"default": False}),
                "aspect_ratio": (
                    default_config.SUPPORTED_NANO_BANANA_AR,
                    {"default": "auto"},
                ),
                "image_1": ("IMAGE",),
                "image_2": ("IMAGE",),
                "image_3": ("IMAGE",),
                "image_4": ("IMAGE",),
                "image_5": ("IMAGE",),
                "image_6": ("IMAGE",),
            },
        }

    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("image", "status")

    @classmethod
    def IS_CHANGED(s, **kwargs):
        return float("NaN")

    def _create_error_result(
        self, error_message: str, original_image: Optional[torch.Tensor] = None
    ) -> Dict[str, Any]:
        print(f"èŠ‚ç‚¹æ‰§è¡Œé”™è¯¯: {error_message}")
        if original_image is not None:
            image_out = original_image
        else:
            image_out = torch.zeros((1, 1, 1, 3), dtype=torch.float32)

        return {
            "ui": {"string": [error_message]},
            "result": (image_out, f"å¤±è´¥: {error_message}"),
        }

    def execute(self, **kwargs):
        grsai_api_key = default_config.get_api_key()
        if not grsai_api_key:
            return self._create_error_result(default_config.api_key_error_message)

        prompt = kwargs.pop("prompt")
        model = kwargs.pop("model")
        
        # [ä¿®æ”¹] è·å– imageSize
        imageSize = kwargs.pop("imageSize", "1K")

        use_aspect_ratio = kwargs.pop("use_aspect_ratio", False)
        aspect_ratio = kwargs.pop("aspect_ratio", None)
        if not use_aspect_ratio:
            aspect_ratio = None
        elif aspect_ratio is None:
            aspect_ratio = "auto"

        # æ”¶é›†å¯é€‰è¾“å…¥å›¾åƒ
        images_in: List[torch.Tensor] = [
            kwargs.get(f"image_{i}")
            for i in range(1, 7)
            if kwargs.get(f"image_{i}") is not None
        ]
        for i in range(1, 7):
            kwargs.pop(f"image_{i}", None)

        uploaded_urls: List[str] = []
        temp_files: List[str] = []

        # è‹¥æä¾›äº†å‚è€ƒå›¾ï¼Œåˆ™ä¸Šä¼ è·å–URL
        if images_in:
            try:
                for i, image_tensor in enumerate(images_in):
                    pil_images = tensor_to_pil(image_tensor)
                    if not pil_images:
                        continue

                    with tempfile.NamedTemporaryFile(
                        suffix=f"_{i}.png", delete=False
                    ) as temp_file:
                        pil_images[0].save(temp_file, "PNG")
                        temp_files.append(temp_file.name)

                    with SuppressFalLogs():
                        uploaded_urls.append(
                            upload_file_zh(
                                api_key=grsai_api_key, file_path=temp_files[-1]
                            )
                        )

                if not uploaded_urls:
                    return self._create_error_result(
                        "All input images could not be processed or uploaded."
                    )
            except Exception as e:
                return self._create_error_result(
                    f"Image upload failed: {format_error_message(e)}"
                )
            finally:
                for path in temp_files:
                    if os.path.exists(path):
                        os.unlink(path)

        # è°ƒç”¨ Nano Banana æ¥å£
        try:
            api_client = GrsaiAPI(api_key=grsai_api_key)
            with SuppressFalLogs():
                pil_images, image_urls, errors = api_client.banana_generate_image(
                    prompt=prompt,
                    model=model,
                    urls=uploaded_urls,
                    aspect_ratio=aspect_ratio,
                    imageSize=imageSize, # ä¼ é€’æ–°å¢å‚æ•°
                )
        except Exception as e:
            return self._create_error_result(
                f"Nano Banana API è°ƒç”¨å¤±è´¥: {format_error_message(e)}"
            )

        if not pil_images:
            error_msg = (
                "All image generations failed."
                if not images_in
                else "Image editing failed."
            )
            detail = f"; {errors}" if errors else ""
            return self._create_error_result(error_msg + detail)

        status = f"Nano Banana | å‚è€ƒå›¾ç‰‡: {len(uploaded_urls)} å¼  | æˆåŠŸç”Ÿæˆ: {len(pil_images)} å¼ "

        return {
            "ui": {"string": [status]},
            "result": (pil_to_tensor(pil_images), status),
        }


NODE_CLASS_MAPPINGS = {
    "Grsai_NanoBanana": GrsaiNanoBanana_Node,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "Grsai_NanoBanana": "ğŸŒ GrsAI Nano Banana - Text/Image",
}
